\documentclass[a4paper, 12pt]{article}

\usepackage{sbc-template}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fontspec}
\usepackage{array}
\usepackage{fixltx2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{a4wide}
\usepackage{array}
\usepackage{multicol}
\usepackage[table]{xcolor}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{setspace}
\usepackage{minted}
\usepackage[bottom]{footmisc}
\usepackage[nottoc]{tocbibind}
\usepackage{listings}
\usepackage[a4paper]{geometry}
\usepackage[square, sort, comma, numbers]{natbib}

\onehalfspacing
\graphicspath{{./img/}}

\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}

\setsansfont{DejaVu Sans}
\setmonofont{DejaVu Sans Mono}

\begin{document}

\hypersetup{backref,pdfpagemode=FullScreen,colorlinks=true}

\thispagestyle{empty}
\begin{center}
    \textbf{\Large{Program Autotuning with \\ Cloud Computing and OpenTuner}}\\

    \vspace*{0.5cm}

    \begin{minipage}{.3\linewidth}
        \begin{flushleft}
            Pedro Bruel\\
            phrb@ime.usp.br
        \end{flushleft}
    \end{minipage}
    \begin{minipage}{.3\linewidth}
        \begin{center}
            Alfredo Goldman\\
            gold@ime.usp.br
        \end{center}
    \end{minipage}
    \begin{minipage}{.3\linewidth}
        \begin{flushright}
            Daniel Batista\\
            batista@ime.usp.br
        \end{flushright}
    \end{minipage}

    \vskip 0.5cm

    \normalsize{Instituto de Matemática e Estatística (IME)\\
                Universidade de São Paulo (USP)\\
                R. do Matão, 1010 – Vila Universitária, São Paulo – SP, 05508-090\\}

\end{center}

\begin{abstract}
    The OpenTuner framework provides domain-agnostic tools for the
    implementation of autotuners. The optimization results are
    obtained sequentially by the measurement driver, that runs
    in a local machine.
    This paper presents an extension to the OpenTuner measurement driver,
    enabling it to leverage cloud computing resources
    from the Google Compute Engine. We compare the performance of
    our implementation using a diverse benchmark.
\end{abstract}

\section{Introduction} \label{sec:intro}

The program autotuning problem fits in the framework of the Algorithm Selection
Problem, introduced by Rice in 1976~\cite{rice1976algorithm}. The objective of
an autotuner is to select the best algorithm, or algorithm configuration, for
each instance of a problem.  Algorithms or configurations are selected
according to performance metrics such as the time to solve the problem
instance, the accuracy of the solution and the energy consumed.  The set of all
possible algorithms and configurations that solve a problem define a
\emph{search space}. Guided by the performance metrics, various optimization
techniques search this space for the algorithm or configuration that best
solves the problem.

Autotuners can specialize in domains such as matrix
multiplication~\cite{bilmes1997phipac}, dense~\cite{whaley1998atlas} or
sparse~\cite{vuduc2005oski} matrix linear algebra, and parallel
programming~\cite{jordan2012multi}. Other autotuning frameworks provide more
general tools for the representation and search of program configurations,
enabling the implementation of autotuners for different problem
domains~\cite{ansel2014opentuner,hutter2009paramils}.

The main contribution of this paper is the implementation of an
extension to the OpenTuner framework~\cite{ansel2014opentuner} that 
enables it to leverage cloud computing resources. 
The interactions between the local and virtual machines follows 
the client-server model. The local machine runs a measurement client that
requests results from various measurement servers running in virtual machines
hosted at the Google Compute Engine.
We compare the performance of our extension with the
unmodified framework in a diverse benchmark of applications, identifying
the problem domains that benefit from this cloud-based approach.

The rest of the paper is organized as follows.
Section~\ref{sec:related} discusses related work.
Section~\ref{sec:ot} discusses the architecture of the OpenTuner framework.
Section~\ref{sec:ext} presents the architecture of the measurement driver
extension, the Google Compute Engine interface and the application protocol
that mediates the interactions between \emph{MeasurementClient} and
\emph{MeasurementServer}s.
Section~\ref{sec:norm} discusses the result normalization strategies.
Section~\ref{sec:exp} describes the experiments performed and the 
applications used in the benchmark.
Section~\ref{sec:results} presents a preliminary schedule.
Section~\ref{sec:conclusion} concludes the proposal.

\section{Related Work} \label{sec:related}

Rice's conceptual framework~\cite{rice1976algorithm} formed the foundation
of autotuners in various problem domains.  In 1997, the PHiPAC
system~\cite{bilmes1997phipac} used code generators and search scripts to
automatically generate high performance code
for matrix multiplication. Since then, systems tackled different domains with a
diversity of strategies. Whaley \emph{et al.}~\cite{whaley1998atlas} introduced
the ATLAS project, that optimizes dense matrix multiply routines. The
OSKI~\cite{vuduc2005oski} library provides automatically tuned kernels for
sparse matrices. The FFTW~\cite{frigo1998fftw} library provides tuned C
subroutines for computing the Discrete Fourier Transform.  In an effort to
provide a common representation of multiple parallel programming models, the
INSIEME compiler project~\cite{jordan2012multi} implements abstractions for
OpenMP, MPI and OpenCL, and generates optimized parallel code for heterogeneous
multi-core architectures.

Some autotuning systems provide generic tools that enable the implementation of
autotuners in various domains. PetaBricks~\cite{ansel2009petabricks} is a
language, compiler and autotuner that introduces abstractions, such as the
\texttt{\footnotesize either...or} construct, that enable programmers to define
multiple algorithms for the same problem.  The ParamILS
framework~\cite{hutter2009paramils} applies stochastic local search methods
for algorithm configuration and parameter tuning.  The OpenTuner
framework~\cite{ansel2014opentuner} provides ensembles of techniques that
search spaces of program configurations. Bosboom \emph{et al.} and Eliahu use
OpenTuner to implement a domain specific language for data-flow
programming~\cite{bosboom2014streamjit} and a framework for recursive parallel
algorithm optimization~\cite{eliahu2015frpa}.

In a progression of papers~\cite{gupta2012exploring,gupta2014evaluating,gupta2013hpccloud},
Gupta \emph{et al.} provide experimental evaluations of the application of
cloud computing to high performance computing, describing which kind of
applications has the greatest potential to benefit from cloud computing.
Their work highlights small and medium scale projects as the main beneficiaries
of cloud computing resources.

\section{OpenTuner} \label{sec:opt}

OpenTuner search spaces are defined by \emph{Configurations}, that are composed
of \emph{Parameter} of various types. Each type has restricted bounds and
manipulation functions that enable the exploration of the search space.
OpenTuner implements ensembles of optimization techniques that
perform well in different problem domains. The framework uses
\emph{meta-techniques} to coordinate the distribution of resources
between techniques.
Results found during search are shared through a
database. An OpenTuner application can implement its own search
techniques and meta-techniques, making the ensemble more robust.
The source code is available\footnote{Hosted at GitHub:
\texttt{\scriptsize github.com/jansel/opentuner}} under the MIT License.

\begin{figure}[htpb]
    \centering
    \includegraphics[scale=.62]{opentuner-implementation}
    \caption{Simplified OpenTuner Architecture.}
    \label{fig:ot-imp}
\end{figure}

Figure~\ref{fig:ot-imp} shows a high-level view of OpenTuner's architecture.
Measurement and searching are done in separate modules, whose main classes are
called \emph{drivers}. The search driver requests measurements by registering
configurations to the database. The measurement driver reads those
configurations and writes back the desired results.  Currently, the
measurements are performed sequentially.

OpenTuner implements optimization techniques such as the
Nelder-Mead~\cite{nelder1965simplex} simplex method and Simulated
Annealing~\cite{kirkpatrick1983optimization}. A resource sharing mechanism,
called \emph{meta-technique}, aims to take advantage of the strengths of each
technique by balancing the exploitation of a technique that has produced good
results in the past and the exploration of unused and possibly better ones.

\section{Measurement Server and Client}
\label{sec:ext}

The interactions between the local and virtual machines will follow the
client-server model. The local machine will run a measurement client, that will
request results from various measurement servers running in virtual machines
hosted at the Google Compute Engine.

\begin{figure}[htpb]
    \centering
    \begin{minipage}{.45\textwidth}
        \centering
        \includegraphics[scale=.62]{high-level-implementation}
        \caption{A high-level view of the proposed architecture.
        Green boxes represent unmodified modules, blue boxes represent
        new or modified modules.}
        \label{fig:high-level}
    \end{minipage}%
    \hfill
    \begin{minipage}{.45\textwidth}
        \centering
        \includegraphics[scale=.62]{low-level-implementation}
        \caption{A lower-level view of the proposed architecture,
        Illustrating the communication between server and client,
        mediated by the Google Compute Engine API.
        }
        \label{fig:low-level}
    \end{minipage}%
    \label{fig:archs}
\end{figure}

Figure~\ref{fig:high-level} shows the proposed architecture of an OpenTuner
application running the measurement client and communicating with the
measurement servers.  Green boxes in the figure represent OpenTuner modules
that will not be modified, and blue boxes represent new or modified modules.

Figure~\ref{fig:low-level} shows, on a lower level of abstraction, the
interactions between the measurement client and servers. A Google Compute
Engine interface and a simple application protocol will be devised to mediate
the requests and responses.  The configurations will be sent to the server,
that will run the correspondent program and respond with the measurement.

OpenTuner controls the execution flow of an application with the
\texttt{\footnotesize main} function of the \texttt{\footnotesize
TuningRunMain} class. This function sets up the database and the search and
measurement modules. It then calls the \texttt{\footnotesize main}
function of the search driver, which runs the main loop of the application.
The search driver generates configurations to be tested and saves
them to the database. It then calls the \texttt{\footnotesize process\_all}
function of the measurement driver and blocks until the function returns.

\input{measurement_client}

The \texttt{\footnotesize process\_all} function is able to compile programs in
parallel, but the measurements are done sequentially.
Listing~\ref{fig:measurement-client} shows the functions of the measurement
driver that will be modified to enable the \texttt{\footnotesize
MeasurementClient} to process results with Google Compute Engine resources.

During its initialization the measurement client will initialize and configure
the virtual machines, storing each measurement server's IP in the GCE
interface.  When the search driver makes requests for results, the
\texttt{\footnotesize process\_all} function will route them to the
servers via the GCE interface.  The interface will call the appropriate GCE
Python API functions, and wait for the responses.

Simple experiments with the Google Compute Engine have been performed. A
project was started and utility functions were implemented, such as
adding and removing virtual machines, configuring firewall access
rules, configuring virtual machines with a startup script and obtaining a
virtual machine's IP.

The utility functions and the measurement server's and client's code are
available\footnote{All code is hosted at GitHub: \\ \texttt{\scriptsize
github.com/phrb/measurement-server} \\ \texttt{\scriptsize
github.com/phrb/autotuning-gce}} under the GNU General Public License.

\section{Normalizing the Results}
\label{sec:norm}

The autotuner will optimize programs for a machine that will typically have an
architectural specification different from the machines in the cloud. A
normalization technique must be devised that enables the results found in the
virtual machines to be valid for the local machine.  Four preliminary
approaches to this problem are discussed in the following. The best approach
will be experimentally determined, and could be combination of the approaches
described here.

\subsubsection{Use OpenTuner to Model Performance}

Another autotuner could be implemented to optimize parameters of a simple
performance model, that would associate a configuration's measurement and the
virtual machine that produced it with a conversion function that transposes
performance results to the target architecture.

\subsubsection{Compose Ensembles of Virtual Machines}

The cloud application could be composed of virtual machines with different
architectures. The final performance measurement for a configuration would be
built from some combination of the results obtained in these different virtual
machines.

\subsubsection{Simulate the Target Architecture}

The target machine could be modeled by an architecture simulator such as
\emph{zsim}~\cite{sanchez2013zsim}, a simulator for multi-core architectures
available\footnote{Hosted at GitHub: \texttt{\scriptsize
https://github.com/s5z/zsim}} under the GNU General Public License.  Using a
simulator would solve the normalization problem but introduce other problems,
such as the simulator's accuracy and performance.

\subsubsection{Run the Autotuner in the Cloud}

Finally, the normalization problem could be sidestepped, at least in initial
stages of research, by running the servers and clients in the cloud using
the same kind of virtual machine.

\section{Experiments} \label{sec:exp}

A benchmark of applications will be composed to compare the performance of the
OpenTuner framework with and without the proposed modifications.  An ideal
benchmark would comprise the applications used to validate
OpenTuner~\cite{ansel2014opentuner}.  The normalization techniques devised for
the results from virtual machines will be compared using the same benchmark.

We expect that the experiments provide insight into the situations when using
cloud computing resources for autotuning is beneficial, and into the
application and efficiency of the result normalization techniques.

\section{Results} \label{sec:results}

\section{Conclusion} \label{sec:conclusion}

This proposal presented a research project aiming to extend the
OpenTuner autotuning framework enabling it to leverage the cloud computing
resources from Google Compute Engine. We believe that distributing
measurements in the cloud will considerably speedup autotuning for every
problem domain.
We propose four approaches to solve the result normalization problem
which would enable transposing the results obtained in virtual machines
to a local machine.
The benchmark for the experiments will be detailed during the development
of the research. It will be composed preferably by problems that evidence
strengths and weaknesses of the cloud environment.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ref}

\end{document}
